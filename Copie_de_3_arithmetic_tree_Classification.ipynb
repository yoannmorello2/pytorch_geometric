{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoannmorello2/pytorch_geometric/blob/master/Copie_de_3_arithmetic_tree_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn5U4EE6K86v",
        "outputId": "b5604aa2-ebe7-4c24-fc0e-1b5d6bfa30f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 28.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 37.6 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-FO5xL3mw98"
      },
      "source": [
        "# Graph Classification with Graph Neural Networks\n",
        "\n",
        "[Previous: Node Classification with Graph Neural Networks](https://colab.research.google.com/drive/14OvFnAXggxB8vM4e8vSURUp1TaKnovzX)\n",
        "\n",
        "In this tutorial session we will have a closer look at how to apply **Graph Neural Networks (GNNs) to the task of graph classification**.\n",
        "Graph classification refers to the problem of classifiying entire graphs (in contrast to nodes), given a **dataset of graphs**, based on some structural graph properties.\n",
        "Here, we want to embed entire graphs, and we want to embed those graphs in such a way so that they are linearly separable given a task at hand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3tBQuI4n7hp"
      },
      "source": [
        "![Screen Shot 2020-08-27 at 13.13.26.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PgzBQEmP7jd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class Tree(object):\n",
        "        def __init__(self, entry, left=None, right=None):\n",
        "            self.entry = entry\n",
        "            self.left = left\n",
        "            self.right = right\n",
        "        def __repr__(self):\n",
        "            args = repr(self.entry)\n",
        "            if self.left or self.right:\n",
        "                args += ', {0}, {1}'.format(repr(self.left), repr(self.right))\n",
        "            return 'Tree({0})'.format(args)\n",
        "        def depth(self):\n",
        "            if self.left == self.right == None:\n",
        "                return 0\n",
        "            elif (self.left !=None)&(self.right !=None):\n",
        "                left_depth = self.left.depth()\n",
        "                right_depth = self.right.depth()\n",
        "                return max(left_depth+1,right_depth+1)\n",
        "        def leaves(self):\n",
        "            if self.left == self.right == None:\n",
        "                return [self.entry]\n",
        "            return self.left.leaves()+self.right.leaves()\n",
        "        def width(self):\n",
        "            return len(self.leaves())\n",
        "        def formula(self):\n",
        "            form = list(str(self.entry))\n",
        "            if self.left or self.right:\n",
        "                form = form + self.right.formula()+[')']\n",
        "                form = ['('] +self.left.formula() + form\n",
        "            return form\n",
        "        def get_nodes(self):  #in the same order as they appear in the formula\n",
        "            form = list(str(self.entry))\n",
        "            if self.left or self.right:\n",
        "                form = form + self.right.get_nodes()\n",
        "                form = self.left.get_nodes() + form\n",
        "            return form\n",
        "        def adj_dim(self):\n",
        "            return len(self.get_nodes())\n",
        "        def absisse_of_left_one(self):\n",
        "            if self.left == None:\n",
        "                return 0\n",
        "            else:\n",
        "                if self.left.left == None: \n",
        "                    return 0\n",
        "                else:\n",
        "                    return self.left.left.adj_dim()\n",
        "        def absisse_of_right_one(self):\n",
        "            if self.right == None:\n",
        "                return 0\n",
        "            else:\n",
        "                if self.right.left == None:\n",
        "                    return 0\n",
        "                else:\n",
        "                    return self.right.left.adj_dim()\n",
        "\n",
        "        def graph(self):  \n",
        "            nodes = self.get_nodes()\n",
        "            dim = self.adj_dim()\n",
        "            if dim == 1:\n",
        "                return nodes, np.zeros((1,1))\n",
        "            left_dim = self.left.adj_dim()\n",
        "            right_dim = self.right.adj_dim()\n",
        "            diag_left = self.left.graph()[1]\n",
        "            diag_right = self.right.graph()[1]\n",
        "            haut = np.concatenate((diag_left,np.zeros((left_dim,dim-left_dim))),axis=1)\n",
        "            bas = np.concatenate((np.zeros((right_dim,dim-right_dim)),diag_right),axis=1)\n",
        "            i_left = self.absisse_of_left_one()\n",
        "            i_right = self.absisse_of_right_one()\n",
        "            haut[i_left,left_dim] = 1\n",
        "            bas[i_right, left_dim] = 1\n",
        "            adj = np. concatenate((haut, np.zeros((1,dim)), bas),axis=0)\n",
        "            return nodes, adj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQaOZBKkUoo0"
      },
      "outputs": [],
      "source": [
        "tree=Tree('+',Tree('*',Tree(4),Tree(2)),Tree('*',Tree(3),Tree(5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i2U9AFepU4iY",
        "outputId": "dd740891-961d-42cc-8030-fecdf36c0989"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Tree('+', Tree('*', Tree(4), Tree(2)), Tree('*', Tree(3), Tree(5)))\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repr(tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDQZl9aOK1J5",
        "outputId": "9f80595a-3e9a-4444-9ffb-613a6e1c6043"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['(', '(', '4', '*', '2', ')', '+', '(', '3', '*', '5', ')', ')']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree.formula()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-LnevmOjwwz",
        "outputId": "f60eadfd-47b3-49c4-fffe-1c9534d23cb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['4', '*', '2', '+', '3', '*', '5'], array([[0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.]]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree.graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qXSc5oMMPi4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def tree_generator(variables, connectors, max_depth):\n",
        "    if max_depth == 0:\n",
        "        return Tree(random.choice(variables))\n",
        "    else:\n",
        "      left_depth = random.randint(0,max_depth-1)\n",
        "      right_depth = random.randint(0,max_depth-1)\n",
        "      return Tree(random.choice(connectors),tree_generator(variables, connectors, left_depth),tree_generator(variables, connectors, left_depth))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tjDGpzZR96Z"
      },
      "outputs": [],
      "source": [
        "class ArithmeticTree(Tree):\n",
        "    def __init__(self, entry, left=None, right=None):\n",
        "        super().__init__(entry, left, right)\n",
        "    def eval(self):\n",
        "        if self.left == None:\n",
        "            return int(self.entry)\n",
        "        else:\n",
        "            if self.entry == '+':\n",
        "                return self.left.eval() + self.right.eval()\n",
        "            if self.entry == '*':\n",
        "                return self.left.eval() * self.right.eval()\n",
        "            if self.entry == '-':\n",
        "                return self.left.eval() - self.right.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEAp3JSMVdnt"
      },
      "outputs": [],
      "source": [
        "def arithmetic_tree_generator(variables, connectors, max_depth):\n",
        "    if max_depth == 0:\n",
        "        return ArithmeticTree(random.choice(variables))\n",
        "    else:\n",
        "      left_depth = random.randint(0,max_depth-1)\n",
        "      right_depth = random.randint(0,max_depth-1)\n",
        "      return ArithmeticTree(random.choice(connectors),arithmetic_tree_generator(variables, connectors, left_depth),arithmetic_tree_generator(variables, connectors, left_depth))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "import networkx as nx\n",
        "def arith_data_gen(variables,connectors, max_depth, n_samples):\n",
        "    data_set = []\n",
        "    for i in range(n_samples):\n",
        "        tree = arithmetic_tree_generator(variables, connectors, max_depth)\n",
        "        graph = tree.graph()\n",
        "        nodes = graph[0]\n",
        "        adj_mat = graph[1]\n",
        "        y = torch.tensor(tree.eval()/10000)\n",
        "        net_graph = nx.from_numpy_matrix(adj_mat,  create_using=nx.DiGraph)\n",
        "        dic_nodes = dict(zip(list(range(tree.adj_dim())), nodes))\n",
        "        nx.set_node_attributes(net_graph,dic_nodes,'x')\n",
        "        #net_graph.graph['y'] = y\n",
        "        data_set.append((net_graph,y))\n",
        "    return data_set"
      ],
      "metadata": {
        "id": "xB6QHSXN6gjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the task with arithmetic expression of max_depth 4 and operators '+' and '*'"
      ],
      "metadata": {
        "id": "RRRnHvpcOq4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variables = list(np.arange(10))\n",
        "connectors = ['+','*']\n",
        "net_data = arith_data_gen(variables, connectors, max_depth=4, n_samples =10000)"
      ],
      "metadata": {
        "id": "Sk60B8shCAgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_data[500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6kTKo4mJbm4",
        "outputId": "bb05910e-f953-46ce-cd65-8ac37f68128e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<networkx.classes.digraph.DiGraph at 0x7faf9442af90>, tensor(72))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we transform our database in a pytorch geometric database\n"
      ],
      "metadata": {
        "id": "bAJWCZKlN8iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "range(*slice(5,8).indices(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjOcAwYCkz99",
        "outputId": "9d13d490-ca97-4f2a-ad94-f18632e0ffa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(5, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.utils.convert import to_networkx, from_networkx\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, net_data, transform=None, target_transform=None):\n",
        "        self.net_data = net_data\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.net_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if isinstance(idx, int):\n",
        "            if idx < 0 : #Handle negative indices\n",
        "              idx += len( self )\n",
        "            else:\n",
        "              pygra = from_networkx(self.net_data[idx][0])\n",
        "              pygra.y = torch.tensor(np.array(self.net_data[idx][1],ndmin=1))\n",
        "              if self.transform:\n",
        "                  pygra.x = self.transform(pygra.x) \n",
        "              \n",
        "            return pygra\n",
        "        elif isinstance(idx, slice ) :\n",
        "            #Get the start, stop, and step from the slice\n",
        "            return [self[ii] for ii in range(*idx.indices(len(self)))]\n",
        "    "
      ],
      "metadata": {
        "id": "bCAP6eXXMwYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class One_Hot_nodes(object):\n",
        "    def __init__(self, variables,connectors):\n",
        "        self.l = len(variables+connectors)\n",
        "        self.map = dict(zip(variables+connectors,range(self.l)))\n",
        "        \n",
        "    def __call__(self,liste):\n",
        "        self.enc = np.zeros((len(liste),self.l))\n",
        "        for i, node in enumerate(liste):\n",
        "            try :\n",
        "                self.enc[i, self.map[int(node)]] = 1\n",
        "            except :\n",
        "                self.enc[i, self.map[node]] = 1\n",
        "        return torch.from_numpy(self.enc)"
      ],
      "metadata": {
        "id": "PCvrMml2oDHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyg_graphs = CustomDataset(net_data,transform = One_Hot_nodes(variables,connectors))"
      ],
      "metadata": {
        "id": "ZvOJeeyFLXjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyg_graphs[0].x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NElRKaIdgiD",
        "outputId": "9fa6271d-b1ae-4a0d-ea66-428eb9f9f2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from_networkx(net_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdLtTBszDTlz",
        "outputId": "03bf40cf-b0af-4ea0-9013-3554fb45b219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[7], edge_index=[2, 6], y=24, weight=[6])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoVJAYgSJSPD"
      },
      "outputs": [],
      "source": [
        " \n",
        "\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pydot\n",
        "from networkx.drawing.nx_pydot import graphviz_layout\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    pos = graphviz_layout(G, prog=\"dot\")\n",
        "    nx.draw_networkx(G, pos=pos, with_labels=True,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_graph(net_graph,'white')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "mA9J4G8ovHK7",
        "outputId": "d08def98-9fe5-413c-809b-5639b9b1393e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-2978485a57fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'net_graph' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pyg_graphs\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "#print(f'Number of features: {dataset.num_features}')\n",
        "#print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0] # Get the first graph object.\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('=============================================================')\n",
        "\n",
        "# Gather some statistics about the first graph.\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjjHZKxmsHHU",
        "outputId": "6844ee03-7468-4024-e598-3947424c14ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: <__main__.CustomDataset object at 0x7faf923c6fd0>:\n",
            "====================\n",
            "Number of graphs: 10000\n",
            "\n",
            "Data(x=[11, 12], edge_index=[2, 10], weight=[10], y=[1])\n",
            "=============================================================\n",
            "Number of nodes: 11\n",
            "Number of edges: 10\n",
            "Average node degree: 0.91\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "b3ZVqIyoHITE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyg_graphs[800]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojputuOSHSfx",
        "outputId": "97a54d6d-5e9a-42a3-ebba-15b0c0b93ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[7, 12], edge_index=[2, 6], weight=[6], y=[1])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHSP6-RBOqCE",
        "outputId": "d50fd967-179e-4768-e5b6-4cafcce4042f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training graphs: 800\n",
            "Number of test graphs: 9200\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset = pyg_graphs\n",
        "train_dataset = dataset[:800]\n",
        "test_dataset = dataset[800:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "JxQlkBiGsK4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step, data in enumerate(train_loader):\n",
        "    print(f'Step {step + 1}:')\n",
        "    print('=======')\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(data.y)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY1KWI5I3GAy",
        "outputId": "6317f111-d447-44a6-a507-b3b6701911e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([0]), array([1080]), array([0]), array([53]), array([1]), array([16]), array([200]), array([1002]), array([63]), array([26]), array([11]), array([23]), array([6]), array([6]), array([16]), array([13]), array([112]), array([9]), array([136080]), array([273]), array([0]), array([6426]), array([1960]), array([1075]), array([6]), array([0]), array([129]), array([60480]), array([486]), array([126]), array([1170]), array([64]), array([78]), array([5]), array([0]), array([62]), array([96]), array([0]), array([104]), array([30]), array([14]), array([630]), array([35251200]), array([3744]), array([78]), array([84]), array([10]), array([4]), array([2802]), array([3]), array([0]), array([579]), array([336]), array([40]), array([1944]), array([21]), array([0]), array([10]), array([34992]), array([31]), array([27]), array([160]), array([559]), array([70])]\n",
            "\n",
            "Step 2:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([14]), array([14]), array([0]), array([3]), array([288]), array([4]), array([8]), array([0]), array([0]), array([0]), array([96]), array([20]), array([10]), array([22]), array([29]), array([144]), array([1344]), array([8]), array([12096]), array([63]), array([51]), array([429]), array([25]), array([5712]), array([144]), array([3192]), array([0]), array([5]), array([720]), array([13]), array([284]), array([70]), array([0]), array([63]), array([20]), array([28]), array([55]), array([30]), array([0]), array([17640]), array([48]), array([4320]), array([5390]), array([875]), array([1256]), array([192]), array([1728]), array([5712]), array([10]), array([69]), array([123]), array([9]), array([15]), array([180]), array([22]), array([0]), array([64]), array([8]), array([34]), array([191]), array([13]), array([1764]), array([324]), array([103])]\n",
            "\n",
            "Step 3:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([8]), array([43]), array([486]), array([777]), array([1404]), array([36]), array([37]), array([37]), array([1056]), array([13]), array([120]), array([34]), array([66]), array([562]), array([8]), array([17]), array([0]), array([0]), array([13]), array([8]), array([42]), array([144]), array([2]), array([0]), array([14]), array([140]), array([36]), array([201]), array([82]), array([50]), array([64]), array([24]), array([2570]), array([83]), array([7]), array([35]), array([24]), array([425]), array([28]), array([120]), array([16]), array([0]), array([6]), array([0]), array([54]), array([10]), array([8]), array([12]), array([5]), array([18]), array([8100]), array([420]), array([14170]), array([224]), array([25]), array([242]), array([9]), array([0]), array([19]), array([0]), array([273]), array([45]), array([15]), array([519])]\n",
            "\n",
            "Step 4:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([285]), array([0]), array([0]), array([101]), array([16]), array([50]), array([0]), array([1127]), array([99]), array([52]), array([66]), array([54]), array([240]), array([9]), array([26]), array([9]), array([0]), array([14]), array([37]), array([96]), array([3678]), array([18]), array([0]), array([1344]), array([11]), array([42]), array([169]), array([795]), array([49]), array([0]), array([88]), array([72]), array([7776]), array([576]), array([634]), array([19]), array([9]), array([81]), array([4]), array([54]), array([42]), array([29]), array([2]), array([10]), array([588]), array([5]), array([247]), array([9]), array([560]), array([192]), array([4]), array([40]), array([24]), array([36]), array([12]), array([56]), array([17]), array([10]), array([30]), array([2430]), array([16]), array([168]), array([84]), array([56])]\n",
            "\n",
            "Step 5:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([49]), array([10]), array([160]), array([0]), array([8]), array([1800]), array([12]), array([0]), array([10]), array([1110]), array([56448]), array([72]), array([49]), array([35]), array([76]), array([138]), array([118]), array([6]), array([36]), array([25]), array([7]), array([99]), array([27]), array([480]), array([15]), array([11]), array([22]), array([8]), array([16800]), array([120]), array([45]), array([52]), array([54]), array([1827]), array([0]), array([900]), array([52]), array([416]), array([204]), array([15]), array([46]), array([50]), array([24]), array([8]), array([27]), array([0]), array([8]), array([32]), array([48]), array([9]), array([319]), array([21]), array([32]), array([294]), array([8]), array([40]), array([98]), array([272]), array([63]), array([25]), array([184]), array([30]), array([15]), array([0])]\n",
            "\n",
            "Step 6:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([444]), array([1350]), array([25]), array([360]), array([1475]), array([85]), array([8]), array([30]), array([864]), array([1680]), array([10]), array([38]), array([401]), array([10]), array([120]), array([73]), array([5]), array([20]), array([9]), array([121]), array([210]), array([4]), array([5]), array([32]), array([72]), array([933]), array([6]), array([40]), array([20]), array([9]), array([100]), array([2240]), array([4]), array([10]), array([69888]), array([0]), array([35]), array([2016]), array([714]), array([221]), array([0]), array([19]), array([30]), array([23]), array([232]), array([85]), array([86]), array([18]), array([732]), array([18]), array([12]), array([0]), array([204]), array([10]), array([12]), array([10]), array([16]), array([48]), array([0]), array([2540160]), array([32]), array([1352]), array([209]), array([196])]\n",
            "\n",
            "Step 7:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([8]), array([112]), array([40248]), array([8]), array([15]), array([4]), array([32]), array([24]), array([14]), array([0]), array([9]), array([50]), array([6720]), array([11]), array([13]), array([315]), array([5376]), array([90]), array([16]), array([4802]), array([12]), array([1344]), array([81]), array([20]), array([3456]), array([6]), array([4725]), array([9]), array([100]), array([280]), array([324]), array([39]), array([48]), array([3240]), array([350]), array([4]), array([32634]), array([140]), array([198]), array([0]), array([32]), array([169]), array([43]), array([15]), array([4]), array([21]), array([225]), array([105]), array([56700]), array([83]), array([21]), array([270]), array([5832]), array([105]), array([16]), array([83]), array([21600]), array([308]), array([198]), array([45]), array([108]), array([66]), array([47]), array([0])]\n",
            "\n",
            "Step 8:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([20]), array([672]), array([16]), array([56]), array([14]), array([32508]), array([84]), array([22]), array([4]), array([3]), array([67]), array([21]), array([67]), array([72]), array([0]), array([60]), array([24]), array([23]), array([22]), array([42]), array([15]), array([395]), array([20]), array([68]), array([420]), array([26]), array([15]), array([104]), array([8]), array([8]), array([10]), array([0]), array([38]), array([448]), array([138]), array([2160]), array([13]), array([24]), array([51]), array([7]), array([0]), array([47]), array([81]), array([9]), array([80]), array([20]), array([468]), array([1]), array([5]), array([920]), array([9]), array([11]), array([147]), array([6]), array([24640]), array([351]), array([2276]), array([7]), array([346]), array([33]), array([3]), array([91]), array([2448]), array([15])]\n",
            "\n",
            "Step 9:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([20]), array([246]), array([49]), array([24]), array([198]), array([4]), array([24]), array([19200]), array([26334]), array([42]), array([16]), array([5]), array([2072]), array([93]), array([37]), array([1008]), array([18]), array([4]), array([3]), array([28]), array([14]), array([58]), array([896]), array([6]), array([525]), array([3]), array([14]), array([56]), array([1890]), array([42]), array([6]), array([0]), array([299]), array([4]), array([0]), array([10]), array([15]), array([248]), array([20]), array([64]), array([2160]), array([36]), array([14]), array([35]), array([48]), array([18]), array([17]), array([0]), array([2583]), array([123]), array([65]), array([1488]), array([7]), array([0]), array([8772]), array([91]), array([30]), array([6]), array([13]), array([0]), array([136]), array([16]), array([255]), array([0])]\n",
            "\n",
            "Step 10:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([480]), array([224]), array([4320]), array([22]), array([792]), array([0]), array([8]), array([1140]), array([9]), array([7]), array([65]), array([28]), array([37]), array([192]), array([13]), array([0]), array([7200]), array([0]), array([12]), array([49]), array([1269]), array([336]), array([39]), array([900]), array([18522]), array([0]), array([12]), array([7]), array([12]), array([16]), array([315]), array([66]), array([0]), array([216]), array([39]), array([52]), array([12]), array([0]), array([10]), array([0]), array([10]), array([324]), array([9]), array([122]), array([2]), array([1017450]), array([10]), array([104]), array([5]), array([502]), array([180]), array([0]), array([5400]), array([84]), array([96832]), array([16]), array([0]), array([140]), array([13]), array([30]), array([6400]), array([10]), array([376]), array([1280])]\n",
            "\n",
            "Step 11:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([504]), array([8]), array([11]), array([72]), array([60]), array([56]), array([121]), array([11]), array([672]), array([25]), array([317]), array([280]), array([33]), array([1248]), array([32]), array([378]), array([252]), array([11]), array([0]), array([416]), array([78]), array([0]), array([3240]), array([32]), array([13]), array([10]), array([12]), array([40]), array([9]), array([12600]), array([15]), array([24]), array([59]), array([0]), array([12]), array([10]), array([19]), array([0]), array([24]), array([243]), array([144]), array([356]), array([364]), array([1386]), array([2646]), array([333]), array([16]), array([212]), array([17]), array([150]), array([360]), array([27]), array([15]), array([0]), array([64]), array([13]), array([31]), array([91]), array([648]), array([189]), array([0]), array([210]), array([66528]), array([7])]\n",
            "\n",
            "Step 12:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "[array([32256]), array([8]), array([4]), array([255]), array([0]), array([5]), array([12]), array([13]), array([1260]), array([0]), array([16]), array([2]), array([8]), array([25]), array([8]), array([24]), array([13]), array([150]), array([23]), array([114]), array([6]), array([138]), array([320]), array([0]), array([14]), array([6]), array([50]), array([33]), array([13]), array([13]), array([120]), array([6]), array([20]), array([35]), array([21]), array([3]), array([2520]), array([260]), array([8]), array([33]), array([1330]), array([8]), array([714]), array([12]), array([12]), array([38]), array([8]), array([27]), array([156]), array([6]), array([234]), array([25]), array([57]), array([81648]), array([42]), array([11]), array([34]), array([42336]), array([708]), array([440]), array([47]), array([23]), array([15]), array([28])]\n",
            "\n",
            "Step 13:\n",
            "=======\n",
            "Number of graphs in the current batch: 32\n",
            "[array([1225]), array([120]), array([0]), array([4]), array([63]), array([0]), array([20]), array([12]), array([80]), array([701]), array([40]), array([1020]), array([2576]), array([9828]), array([9]), array([0]), array([12]), array([20]), array([56]), array([27]), array([2856]), array([0]), array([18]), array([152]), array([720]), array([612]), array([37632]), array([17]), array([0]), array([181]), array([28]), array([11])]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "         out = model(data.x.float(), data.edge_index, data.batch)\n",
        "         print(out.dtype)\n",
        "         print(data.y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhICqsMoFLMP",
        "outputId": "ffcf44e0-c49d-4bd0-d05c-9bd4b4c5e2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(12, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # 1. Obtain node embeddings \n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = torch.squeeze(self.lin(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=64)\n",
        "#model = model.float()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWcl3ScatfB1",
        "outputId": "7741b8d8-a062-4c1e-97a9-541a97b7ebcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(12, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (conv4): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShZVO-SwJXjQ",
        "outputId": "f9e3c3c5-0f58-414a-e0a3-95ffd38db352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7faf93b0e250>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = GCN(hidden_channels=64)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
        "         out = model(data.x.float(), data.edge_index, data.batch)  # Perform a single forward pass.\n",
        "         loss = criterion(out, data.y.float())  # Compute the loss.\n",
        "         loss.backward()  # Derive gradients.\n",
        "         optimizer.step()  # Update parameters based on gradients.\n",
        "         optimizer.zero_grad()  # Clear gradients.\n",
        "         print(f'Loss: {loss:.4f}')\n",
        "         \n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
        "         out = model(data.x.float(), data.edge_index, data.batch)  \n",
        "         pred = out  \n",
        "         correct += int(torch.mul((data.y-1 < pred),(pred < data.y+1)).sum())  # Check against ground-truth labels.\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
        "\n",
        "\n",
        "for epoch in range(1, 100):\n",
        "    train()\n",
        "    train_acc = test(train_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f'Epoch: {epoch:03d},  Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "d82C1VxGudix",
        "outputId": "cb92bc9b-2f79-4799-dad4-8ac5afe08b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 3.8756\n",
            "Loss: 7631.4209\n",
            "Loss: 0.0601\n",
            "Loss: 0.0684\n",
            "Loss: 0.5933\n",
            "Loss: 0.2983\n",
            "Loss: 0.3222\n",
            "Loss: 4023.9817\n",
            "Loss: 2.0799\n",
            "Loss: 0.6871\n",
            "Loss: 5103.3052\n",
            "Loss: 1.8628\n",
            "Loss: 0.0041\n",
            "Epoch: 001,  Train Acc: 0.9650, Test Acc: 0.9662\n",
            "Loss: 3.9392\n",
            "Loss: 32.2394\n",
            "Loss: 7630.2109\n",
            "Loss: 2.0938\n",
            "Loss: 0.0932\n",
            "Loss: 0.6416\n",
            "Loss: 3990.8210\n",
            "Loss: 0.0097\n",
            "Loss: 5102.6172\n",
            "Loss: 0.0106\n",
            "Loss: 1.8127\n",
            "Loss: 0.9283\n",
            "Loss: 0.0160\n",
            "Epoch: 002,  Train Acc: 0.9663, Test Acc: 0.9668\n",
            "Loss: 0.5269\n",
            "Loss: 1.4039\n",
            "Loss: 3.7199\n",
            "Loss: 0.8950\n",
            "Loss: 0.0199\n",
            "Loss: 0.5670\n",
            "Loss: 3990.0378\n",
            "Loss: 12762.3467\n",
            "Loss: 0.0478\n",
            "Loss: 0.0293\n",
            "Loss: 0.7640\n",
            "Loss: 2.0713\n",
            "Loss: 1.1841\n",
            "Epoch: 003,  Train Acc: 0.9663, Test Acc: 0.9680\n",
            "Loss: 0.2150\n",
            "Loss: 0.5269\n",
            "Loss: 5102.3608\n",
            "Loss: 7625.3989\n",
            "Loss: 0.3013\n",
            "Loss: 0.0869\n",
            "Loss: 0.0890\n",
            "Loss: 1.1527\n",
            "Loss: 32.5448\n",
            "Loss: 3985.5835\n",
            "Loss: 0.9124\n",
            "Loss: 1.3848\n",
            "Loss: 0.4531\n",
            "Epoch: 004,  Train Acc: 0.9688, Test Acc: 0.9700\n",
            "Loss: 5100.2407\n",
            "Loss: 0.4020\n",
            "Loss: 32.0337\n",
            "Loss: 0.1906\n",
            "Loss: 0.4225\n",
            "Loss: 0.7398\n",
            "Loss: 3.7233\n",
            "Loss: 0.7193\n",
            "Loss: 11608.2617\n",
            "Loss: 0.4439\n",
            "Loss: 1.4259\n",
            "Loss: 3.0548\n",
            "Loss: 0.4042\n",
            "Epoch: 005,  Train Acc: 0.9750, Test Acc: 0.9720\n",
            "Loss: 7648.8970\n",
            "Loss: 0.4012\n",
            "Loss: 3.8679\n",
            "Loss: 3986.4844\n",
            "Loss: 0.5254\n",
            "Loss: 5085.5210\n",
            "Loss: 1.8863\n",
            "Loss: 2.5382\n",
            "Loss: 2.4749\n",
            "Loss: 1.1919\n",
            "Loss: 0.9278\n",
            "Loss: 1.0625\n",
            "Loss: 1.0379\n",
            "Epoch: 006,  Train Acc: 0.3362, Test Acc: 0.3101\n",
            "Loss: 1.2791\n",
            "Loss: 1.5043\n",
            "Loss: 3974.7739\n",
            "Loss: 2.2166\n",
            "Loss: 2.8408\n",
            "Loss: 1.2059\n",
            "Loss: 7644.5479\n",
            "Loss: 1.1115\n",
            "Loss: 1.4840\n",
            "Loss: 1.6025\n",
            "Loss: 5086.4111\n",
            "Loss: 1.4994\n",
            "Loss: 1.4334\n",
            "Epoch: 007,  Train Acc: 0.0612, Test Acc: 0.0521\n",
            "Loss: 2.6849\n",
            "Loss: 7590.3838\n",
            "Loss: 1.9458\n",
            "Loss: 31.8484\n",
            "Loss: 5066.2324\n",
            "Loss: 2.7041\n",
            "Loss: 3.0874\n",
            "Loss: 3.0782\n",
            "Loss: 3969.7510\n",
            "Loss: 4.3829\n",
            "Loss: 6.7103\n",
            "Loss: 4.0485\n",
            "Loss: 4.9129\n",
            "Epoch: 008,  Train Acc: 0.0187, Test Acc: 0.0168\n",
            "Loss: 4.5441\n",
            "Loss: 7580.6714\n",
            "Loss: 4.4826\n",
            "Loss: 4.8748\n",
            "Loss: 4.6539\n",
            "Loss: 5.1069\n",
            "Loss: 4.8702\n",
            "Loss: 7.2722\n",
            "Loss: 9056.4033\n",
            "Loss: 4.7364\n",
            "Loss: 6.1149\n",
            "Loss: 4.6996\n",
            "Loss: 5.0244\n",
            "Epoch: 009,  Train Acc: 0.0175, Test Acc: 0.0154\n",
            "Loss: 33.5343\n",
            "Loss: 4.6166\n",
            "Loss: 5047.0825\n",
            "Loss: 5.5356\n",
            "Loss: 5.2269\n",
            "Loss: 4.2321\n",
            "Loss: 3973.9417\n",
            "Loss: 7592.2817\n",
            "Loss: 5.9097\n",
            "Loss: 5.9536\n",
            "Loss: 6.0876\n",
            "Loss: 5.3362\n",
            "Loss: 9.1508\n",
            "Epoch: 010,  Train Acc: 0.0125, Test Acc: 0.0145\n",
            "Loss: 5074.2231\n",
            "Loss: 8.2583\n",
            "Loss: 33.0178\n",
            "Loss: 4.7756\n",
            "Loss: 5.6913\n",
            "Loss: 3963.9824\n",
            "Loss: 5.1245\n",
            "Loss: 4.4068\n",
            "Loss: 4.6265\n",
            "Loss: 7566.8149\n",
            "Loss: 4.6404\n",
            "Loss: 6.0678\n",
            "Loss: 6.4620\n",
            "Epoch: 011,  Train Acc: 0.0125, Test Acc: 0.0150\n",
            "Loss: 7.0209\n",
            "Loss: 4.6108\n",
            "Loss: 5059.2539\n",
            "Loss: 5.0131\n",
            "Loss: 5.8325\n",
            "Loss: 35.8572\n",
            "Loss: 6.1271\n",
            "Loss: 7573.5698\n",
            "Loss: 5.2295\n",
            "Loss: 3945.3433\n",
            "Loss: 5.5133\n",
            "Loss: 5.8164\n",
            "Loss: 5.9888\n",
            "Epoch: 012,  Train Acc: 0.0175, Test Acc: 0.0198\n",
            "Loss: 7.7832\n",
            "Loss: 6.8280\n",
            "Loss: 6.1057\n",
            "Loss: 35.8419\n",
            "Loss: 5047.9116\n",
            "Loss: 5.6227\n",
            "Loss: 11531.9951\n",
            "Loss: 6.6847\n",
            "Loss: 6.4208\n",
            "Loss: 7.5626\n",
            "Loss: 5.6757\n",
            "Loss: 7.4286\n",
            "Loss: 7.1835\n",
            "Epoch: 013,  Train Acc: 0.0250, Test Acc: 0.0240\n",
            "Loss: 7559.3755\n",
            "Loss: 7.6501\n",
            "Loss: 34.7173\n",
            "Loss: 7.5065\n",
            "Loss: 5057.9326\n",
            "Loss: 6.5185\n",
            "Loss: 7.1024\n",
            "Loss: 8.9333\n",
            "Loss: 8.1704\n",
            "Loss: 6.4352\n",
            "Loss: 3920.2825\n",
            "Loss: 7.7740\n",
            "Loss: 7.1997\n",
            "Epoch: 014,  Train Acc: 0.0262, Test Acc: 0.0280\n",
            "Loss: 6.8365\n",
            "Loss: 8.2920\n",
            "Loss: 7.0051\n",
            "Loss: 7.1977\n",
            "Loss: 6.3793\n",
            "Loss: 5.3476\n",
            "Loss: 3946.6973\n",
            "Loss: 7550.3423\n",
            "Loss: 32.8937\n",
            "Loss: 6.4200\n",
            "Loss: 6.9489\n",
            "Loss: 5046.7139\n",
            "Loss: 6.3260\n",
            "Epoch: 015,  Train Acc: 0.0413, Test Acc: 0.0389\n",
            "Loss: 7.1674\n",
            "Loss: 5.3867\n",
            "Loss: 8.7135\n",
            "Loss: 6.9581\n",
            "Loss: 3962.1221\n",
            "Loss: 5034.6758\n",
            "Loss: 7573.2236\n",
            "Loss: 34.4413\n",
            "Loss: 7.6525\n",
            "Loss: 8.0676\n",
            "Loss: 10.6947\n",
            "Loss: 9.7510\n",
            "Loss: 8.8170\n",
            "Epoch: 016,  Train Acc: 0.0387, Test Acc: 0.0366\n",
            "Loss: 8.3419\n",
            "Loss: 35.3988\n",
            "Loss: 8.1015\n",
            "Loss: 8.2136\n",
            "Loss: 7.4883\n",
            "Loss: 5051.2729\n",
            "Loss: 3945.9146\n",
            "Loss: 7.3408\n",
            "Loss: 5.9305\n",
            "Loss: 7530.9214\n",
            "Loss: 9.4210\n",
            "Loss: 6.0663\n",
            "Loss: 10.0179\n",
            "Epoch: 017,  Train Acc: 0.0537, Test Acc: 0.0487\n",
            "Loss: 7602.7207\n",
            "Loss: 8.0204\n",
            "Loss: 8.6130\n",
            "Loss: 8.9091\n",
            "Loss: 3938.9019\n",
            "Loss: 8.2270\n",
            "Loss: 8.7725\n",
            "Loss: 9.4492\n",
            "Loss: 32.1956\n",
            "Loss: 5.7058\n",
            "Loss: 5054.8965\n",
            "Loss: 6.7998\n",
            "Loss: 6.5730\n",
            "Epoch: 018,  Train Acc: 0.1113, Test Acc: 0.1033\n",
            "Loss: 11469.0146\n",
            "Loss: 6.5379\n",
            "Loss: 6.1633\n",
            "Loss: 35.5319\n",
            "Loss: 8.4351\n",
            "Loss: 5019.9287\n",
            "Loss: 7.5088\n",
            "Loss: 7.5463\n",
            "Loss: 7.9544\n",
            "Loss: 8.2190\n",
            "Loss: 8.5855\n",
            "Loss: 7.1932\n",
            "Loss: 11.2445\n",
            "Epoch: 019,  Train Acc: 0.1475, Test Acc: 0.1492\n",
            "Loss: 6.5060\n",
            "Loss: 7.0061\n",
            "Loss: 4.1493\n",
            "Loss: 4.3746\n",
            "Loss: 4.1201\n",
            "Loss: 7626.0400\n",
            "Loss: 5084.5591\n",
            "Loss: 5.1625\n",
            "Loss: 4.1314\n",
            "Loss: 4.1762\n",
            "Loss: 3964.4370\n",
            "Loss: 3.1796\n",
            "Loss: 4.3928\n",
            "Epoch: 020,  Train Acc: 0.2250, Test Acc: 0.2151\n",
            "Loss: 7528.6509\n",
            "Loss: 5.1631\n",
            "Loss: 5.2661\n",
            "Loss: 5052.6484\n",
            "Loss: 6.7383\n",
            "Loss: 8.0593\n",
            "Loss: 7.5973\n",
            "Loss: 8.5770\n",
            "Loss: 11.1973\n",
            "Loss: 11.6714\n",
            "Loss: 8.1967\n",
            "Loss: 8.6567\n",
            "Loss: 7819.5659\n",
            "Epoch: 021,  Train Acc: 0.1212, Test Acc: 0.1190\n",
            "Loss: 8.0718\n",
            "Loss: 8.8830\n",
            "Loss: 3933.9807\n",
            "Loss: 8.8976\n",
            "Loss: 11.0442\n",
            "Loss: 5050.4038\n",
            "Loss: 12.6693\n",
            "Loss: 12.7171\n",
            "Loss: 10.9312\n",
            "Loss: 15.1957\n",
            "Loss: 13.5198\n",
            "Loss: 7591.3232\n",
            "Loss: 8.8184\n",
            "Epoch: 022,  Train Acc: 0.1037, Test Acc: 0.0993\n",
            "Loss: 10.5556\n",
            "Loss: 10.3174\n",
            "Loss: 9.0193\n",
            "Loss: 7.8259\n",
            "Loss: 5061.2192\n",
            "Loss: 12.1286\n",
            "Loss: 9.4588\n",
            "Loss: 8.6757\n",
            "Loss: 3945.3369\n",
            "Loss: 9.3564\n",
            "Loss: 6.6053\n",
            "Loss: 7547.4106\n",
            "Loss: 6.3408\n",
            "Epoch: 023,  Train Acc: 0.2250, Test Acc: 0.2141\n",
            "Loss: 7.1514\n",
            "Loss: 6.4816\n",
            "Loss: 5.7945\n",
            "Loss: 9.9365\n",
            "Loss: 5.6676\n",
            "Loss: 3933.7551\n",
            "Loss: 7.3520\n",
            "Loss: 5.9596\n",
            "Loss: 5110.6504\n",
            "Loss: 5.7718\n",
            "Loss: 5.1414\n",
            "Loss: 10.1914\n",
            "Loss: 15029.0068\n",
            "Epoch: 024,  Train Acc: 0.2662, Test Acc: 0.2413\n",
            "Loss: 5.2106\n",
            "Loss: 8.6024\n",
            "Loss: 38.5127\n",
            "Loss: 7.8224\n",
            "Loss: 11.2157\n",
            "Loss: 8.3355\n",
            "Loss: 10.9099\n",
            "Loss: 8.4992\n",
            "Loss: 11431.2852\n",
            "Loss: 10.2840\n",
            "Loss: 5035.6875\n",
            "Loss: 10.1551\n",
            "Loss: 13.3307\n",
            "Epoch: 025,  Train Acc: 0.1550, Test Acc: 0.1473\n",
            "Loss: 11.5763\n",
            "Loss: 13.3151\n",
            "Loss: 11.4582\n",
            "Loss: 38.3786\n",
            "Loss: 18.7321\n",
            "Loss: 3917.2422\n",
            "Loss: 15.3415\n",
            "Loss: 14.3280\n",
            "Loss: 12.6437\n",
            "Loss: 8.0733\n",
            "Loss: 5046.7988\n",
            "Loss: 10.5974\n",
            "Loss: 14870.9893\n",
            "Epoch: 026,  Train Acc: 0.1762, Test Acc: 0.1685\n",
            "Loss: 10.8643\n",
            "Loss: 9.3106\n",
            "Loss: 14.9172\n",
            "Loss: 17.2770\n",
            "Loss: 15.4918\n",
            "Loss: 18.4755\n",
            "Loss: 20.1556\n",
            "Loss: 15.5734\n",
            "Loss: 5052.1733\n",
            "Loss: 15.9975\n",
            "Loss: 11408.9912\n",
            "Loss: 18.1303\n",
            "Loss: 18.9587\n",
            "Epoch: 027,  Train Acc: 0.1338, Test Acc: 0.1280\n",
            "Loss: 18.2212\n",
            "Loss: 14.0400\n",
            "Loss: 7456.6738\n",
            "Loss: 3899.0198\n",
            "Loss: 21.2346\n",
            "Loss: 49.4160\n",
            "Loss: 25.0972\n",
            "Loss: 22.3715\n",
            "Loss: 5052.5928\n",
            "Loss: 19.9005\n",
            "Loss: 21.2501\n",
            "Loss: 19.1677\n",
            "Loss: 10.3505\n",
            "Epoch: 028,  Train Acc: 0.2125, Test Acc: 0.1780\n",
            "Loss: 18.2771\n",
            "Loss: 9.2658\n",
            "Loss: 13.9504\n",
            "Loss: 9.9564\n",
            "Loss: 11.6937\n",
            "Loss: 10.5032\n",
            "Loss: 8.5108\n",
            "Loss: 8.2553\n",
            "Loss: 3935.6079\n",
            "Loss: 33.6789\n",
            "Loss: 12629.5225\n",
            "Loss: 7.7149\n",
            "Loss: 9.4671\n",
            "Epoch: 029,  Train Acc: 0.2888, Test Acc: 0.2453\n",
            "Loss: 8.6706\n",
            "Loss: 3960.1311\n",
            "Loss: 7.6861\n",
            "Loss: 7446.0674\n",
            "Loss: 12.6402\n",
            "Loss: 5016.5781\n",
            "Loss: 20.4289\n",
            "Loss: 17.1990\n",
            "Loss: 19.8630\n",
            "Loss: 24.0101\n",
            "Loss: 19.7843\n",
            "Loss: 20.1836\n",
            "Loss: 21.7233\n",
            "Epoch: 030,  Train Acc: 0.1288, Test Acc: 0.1258\n",
            "Loss: 18.5426\n",
            "Loss: 3893.0078\n",
            "Loss: 17.6621\n",
            "Loss: 50.5639\n",
            "Loss: 16.9212\n",
            "Loss: 21.5530\n",
            "Loss: 16.0088\n",
            "Loss: 12474.4463\n",
            "Loss: 12.6353\n",
            "Loss: 14.9196\n",
            "Loss: 15.4416\n",
            "Loss: 15.0563\n",
            "Loss: 17.8333\n",
            "Epoch: 031,  Train Acc: 0.1475, Test Acc: 0.1510\n",
            "Loss: 12.3588\n",
            "Loss: 11356.6123\n",
            "Loss: 16.2190\n",
            "Loss: 21.2792\n",
            "Loss: 16.3601\n",
            "Loss: 15.0251\n",
            "Loss: 35.7754\n",
            "Loss: 4983.4746\n",
            "Loss: 16.0166\n",
            "Loss: 14.0925\n",
            "Loss: 12.3945\n",
            "Loss: 13.7065\n",
            "Loss: 18.1898\n",
            "Epoch: 032,  Train Acc: 0.1862, Test Acc: 0.1728\n",
            "Loss: 14.4830\n",
            "Loss: 13.7821\n",
            "Loss: 5020.9873\n",
            "Loss: 43.0972\n",
            "Loss: 9.4497\n",
            "Loss: 10.7276\n",
            "Loss: 10.6978\n",
            "Loss: 12.2061\n",
            "Loss: 11.9732\n",
            "Loss: 7466.6846\n",
            "Loss: 9.2439\n",
            "Loss: 11.3064\n",
            "Loss: 7869.4155\n",
            "Epoch: 033,  Train Acc: 0.2512, Test Acc: 0.2107\n",
            "Loss: 10.0493\n",
            "Loss: 11.1352\n",
            "Loss: 11.7519\n",
            "Loss: 14.8428\n",
            "Loss: 9.2866\n",
            "Loss: 5053.5894\n",
            "Loss: 13.0738\n",
            "Loss: 15.3448\n",
            "Loss: 12.7715\n",
            "Loss: 11344.3252\n",
            "Loss: 6.5980\n",
            "Loss: 39.5644\n",
            "Loss: 11.0036\n",
            "Epoch: 034,  Train Acc: 0.2288, Test Acc: 0.2005\n",
            "Loss: 16.5928\n",
            "Loss: 5057.2271\n",
            "Loss: 8.5717\n",
            "Loss: 7490.1450\n",
            "Loss: 19.6398\n",
            "Loss: 14.1208\n",
            "Loss: 12.0268\n",
            "Loss: 15.7208\n",
            "Loss: 17.9113\n",
            "Loss: 34.1943\n",
            "Loss: 3911.6414\n",
            "Loss: 13.9267\n",
            "Loss: 13.4186\n",
            "Epoch: 035,  Train Acc: 0.2000, Test Acc: 0.1817\n",
            "Loss: 13.1443\n",
            "Loss: 14.8914\n",
            "Loss: 14.8563\n",
            "Loss: 5053.8081\n",
            "Loss: 15.5848\n",
            "Loss: 12.9869\n",
            "Loss: 14.3887\n",
            "Loss: 41.4265\n",
            "Loss: 7536.4272\n",
            "Loss: 7.7859\n",
            "Loss: 11.1183\n",
            "Loss: 3903.0125\n",
            "Loss: 11.0221\n",
            "Epoch: 036,  Train Acc: 0.2625, Test Acc: 0.2216\n",
            "Loss: 35.1087\n",
            "Loss: 8.2796\n",
            "Loss: 5026.9106\n",
            "Loss: 9.3727\n",
            "Loss: 12.9425\n",
            "Loss: 7480.6396\n",
            "Loss: 13.3147\n",
            "Loss: 15.2204\n",
            "Loss: 3951.5554\n",
            "Loss: 13.3218\n",
            "Loss: 13.3837\n",
            "Loss: 9.2320\n",
            "Loss: 16.1268\n",
            "Epoch: 037,  Train Acc: 0.2462, Test Acc: 0.2103\n",
            "Loss: 33.5372\n",
            "Loss: 7454.4561\n",
            "Loss: 5030.2168\n",
            "Loss: 10.4496\n",
            "Loss: 14.7409\n",
            "Loss: 22.0240\n",
            "Loss: 13.7335\n",
            "Loss: 16.1225\n",
            "Loss: 3899.9607\n",
            "Loss: 11.1834\n",
            "Loss: 19.1036\n",
            "Loss: 14.1674\n",
            "Loss: 14.3592\n",
            "Epoch: 038,  Train Acc: 0.2238, Test Acc: 0.1920\n",
            "Loss: 14.3849\n",
            "Loss: 15.3486\n",
            "Loss: 9.1655\n",
            "Loss: 5052.1187\n",
            "Loss: 44.1502\n",
            "Loss: 7530.0864\n",
            "Loss: 12.2460\n",
            "Loss: 13.0951\n",
            "Loss: 10.9887\n",
            "Loss: 12.8497\n",
            "Loss: 3917.9651\n",
            "Loss: 12.4941\n",
            "Loss: 6.4294\n",
            "Epoch: 039,  Train Acc: 0.2687, Test Acc: 0.2251\n",
            "Loss: 13.6440\n",
            "Loss: 14.7293\n",
            "Loss: 14.7646\n",
            "Loss: 9.5360\n",
            "Loss: 36.2929\n",
            "Loss: 9.6282\n",
            "Loss: 4997.4966\n",
            "Loss: 11.0840\n",
            "Loss: 10.3290\n",
            "Loss: 9.5327\n",
            "Loss: 11394.0439\n",
            "Loss: 9.8929\n",
            "Loss: 6.3034\n",
            "Epoch: 040,  Train Acc: 0.2762, Test Acc: 0.2379\n",
            "Loss: 15.8770\n",
            "Loss: 10.7688\n",
            "Loss: 8.7635\n",
            "Loss: 11.5275\n",
            "Loss: 10.0030\n",
            "Loss: 8.5271\n",
            "Loss: 10.0249\n",
            "Loss: 40.2194\n",
            "Loss: 11.3142\n",
            "Loss: 11448.3340\n",
            "Loss: 14.3645\n",
            "Loss: 5055.8291\n",
            "Loss: 17.6060\n",
            "Epoch: 041,  Train Acc: 0.2575, Test Acc: 0.2257\n",
            "Loss: 8.0740\n",
            "Loss: 7508.4736\n",
            "Loss: 11.2030\n",
            "Loss: 12.2723\n",
            "Loss: 11.7146\n",
            "Loss: 13.1544\n",
            "Loss: 16.1103\n",
            "Loss: 8887.5371\n",
            "Loss: 17.3270\n",
            "Loss: 37.9780\n",
            "Loss: 16.5876\n",
            "Loss: 10.3622\n",
            "Loss: 10.3740\n",
            "Epoch: 042,  Train Acc: 0.2013, Test Acc: 0.1899\n",
            "Loss: 7531.4004\n",
            "Loss: 14.8344\n",
            "Loss: 11.1560\n",
            "Loss: 20.2531\n",
            "Loss: 17.7929\n",
            "Loss: 21.6496\n",
            "Loss: 33.5308\n",
            "Loss: 8.8952\n",
            "Loss: 14.5276\n",
            "Loss: 3900.2961\n",
            "Loss: 4998.6245\n",
            "Loss: 15.2709\n",
            "Loss: 19.9863\n",
            "Epoch: 043,  Train Acc: 0.2462, Test Acc: 0.2160\n",
            "Loss: 3884.6448\n",
            "Loss: 14.8457\n",
            "Loss: 15.0901\n",
            "Loss: 18.9379\n",
            "Loss: 7480.3589\n",
            "Loss: 10.9776\n",
            "Loss: 35.5644\n",
            "Loss: 11.5715\n",
            "Loss: 13.4095\n",
            "Loss: 5002.1831\n",
            "Loss: 14.4735\n",
            "Loss: 14.9540\n",
            "Loss: 16.1145\n",
            "Epoch: 044,  Train Acc: 0.2125, Test Acc: 0.1903\n",
            "Loss: 15.5913\n",
            "Loss: 22.5596\n",
            "Loss: 3891.4282\n",
            "Loss: 8.3529\n",
            "Loss: 16.0379\n",
            "Loss: 5033.1885\n",
            "Loss: 12.2081\n",
            "Loss: 15.5588\n",
            "Loss: 12.9911\n",
            "Loss: 16.6361\n",
            "Loss: 7473.3184\n",
            "Loss: 13.3199\n",
            "Loss: 13.9977\n",
            "Epoch: 045,  Train Acc: 0.2412, Test Acc: 0.2070\n",
            "Loss: 5012.5786\n",
            "Loss: 3911.6511\n",
            "Loss: 13.5510\n",
            "Loss: 15.2663\n",
            "Loss: 19.0928\n",
            "Loss: 15.2803\n",
            "Loss: 10.7233\n",
            "Loss: 7590.2134\n",
            "Loss: 12.8805\n",
            "Loss: 21.3983\n",
            "Loss: 35.1751\n",
            "Loss: 13.3782\n",
            "Loss: 19.5977\n",
            "Epoch: 046,  Train Acc: 0.2412, Test Acc: 0.2146\n",
            "Loss: 15.2653\n",
            "Loss: 12.2763\n",
            "Loss: 3919.5632\n",
            "Loss: 5034.0112\n",
            "Loss: 34.2621\n",
            "Loss: 16.2687\n",
            "Loss: 15.5954\n",
            "Loss: 10.0275\n",
            "Loss: 7.9550\n",
            "Loss: 7.6849\n",
            "Loss: 13.2513\n",
            "Loss: 10.7186\n",
            "Loss: 15008.5391\n",
            "Epoch: 047,  Train Acc: 0.2838, Test Acc: 0.2529\n",
            "Loss: 5008.3584\n",
            "Loss: 12.1466\n",
            "Loss: 8.5705\n",
            "Loss: 12.5841\n",
            "Loss: 14.0222\n",
            "Loss: 14.0508\n",
            "Loss: 7495.5308\n",
            "Loss: 13.6576\n",
            "Loss: 12.5914\n",
            "Loss: 13.7580\n",
            "Loss: 3952.3547\n",
            "Loss: 14.2635\n",
            "Loss: 15.3035\n",
            "Epoch: 048,  Train Acc: 0.2112, Test Acc: 0.1965\n",
            "Loss: 12.1356\n",
            "Loss: 20.2634\n",
            "Loss: 5007.2183\n",
            "Loss: 44.3769\n",
            "Loss: 12.7318\n",
            "Loss: 7493.2207\n",
            "Loss: 16.8171\n",
            "Loss: 14.1899\n",
            "Loss: 9.3708\n",
            "Loss: 3862.5737\n",
            "Loss: 15.8765\n",
            "Loss: 17.4629\n",
            "Loss: 14.1897\n",
            "Epoch: 049,  Train Acc: 0.2000, Test Acc: 0.1910\n",
            "Loss: 11.6426\n",
            "Loss: 7472.9561\n",
            "Loss: 23.8102\n",
            "Loss: 17.7135\n",
            "Loss: 14.0854\n",
            "Loss: 21.3087\n",
            "Loss: 5025.8164\n",
            "Loss: 17.4450\n",
            "Loss: 23.5038\n",
            "Loss: 10.7489\n",
            "Loss: 3928.5491\n",
            "Loss: 37.9671\n",
            "Loss: 12.7375\n",
            "Epoch: 050,  Train Acc: 0.2437, Test Acc: 0.2197\n",
            "Loss: 15.0940\n",
            "Loss: 3937.4812\n",
            "Loss: 7501.9590\n",
            "Loss: 13.2175\n",
            "Loss: 14.5123\n",
            "Loss: 16.6054\n",
            "Loss: 5021.4795\n",
            "Loss: 34.3698\n",
            "Loss: 12.7942\n",
            "Loss: 14.7651\n",
            "Loss: 14.7464\n",
            "Loss: 13.8620\n",
            "Loss: 14.3724\n",
            "Epoch: 051,  Train Acc: 0.2537, Test Acc: 0.2304\n",
            "Loss: 14.2828\n",
            "Loss: 12.5758\n",
            "Loss: 5040.4946\n",
            "Loss: 13.9151\n",
            "Loss: 10.5292\n",
            "Loss: 11.5093\n",
            "Loss: 7495.6963\n",
            "Loss: 32.8748\n",
            "Loss: 12.0284\n",
            "Loss: 9.7630\n",
            "Loss: 8.4004\n",
            "Loss: 3906.8020\n",
            "Loss: 11.4800\n",
            "Epoch: 052,  Train Acc: 0.2850, Test Acc: 0.2499\n",
            "Loss: 12.2898\n",
            "Loss: 8954.6865\n",
            "Loss: 12.5172\n",
            "Loss: 11.0869\n",
            "Loss: 12.7700\n",
            "Loss: 16.1691\n",
            "Loss: 9.8361\n",
            "Loss: 7453.9531\n",
            "Loss: 17.6477\n",
            "Loss: 10.7163\n",
            "Loss: 16.4411\n",
            "Loss: 12.4703\n",
            "Loss: 11.8813\n",
            "Epoch: 053,  Train Acc: 0.2213, Test Acc: 0.2072\n",
            "Loss: 9.3240\n",
            "Loss: 12.3456\n",
            "Loss: 8.5859\n",
            "Loss: 9.7550\n",
            "Loss: 14.1944\n",
            "Loss: 3899.5337\n",
            "Loss: 7454.6470\n",
            "Loss: 12.3985\n",
            "Loss: 4999.3906\n",
            "Loss: 13.8031\n",
            "Loss: 15.6667\n",
            "Loss: 38.4999\n",
            "Loss: 13.4138\n",
            "Epoch: 054,  Train Acc: 0.2175, Test Acc: 0.2053\n",
            "Loss: 12.4848\n",
            "Loss: 20.2946\n",
            "Loss: 11.8436\n",
            "Loss: 13.2920\n",
            "Loss: 5015.4487\n",
            "Loss: 13.9663\n",
            "Loss: 7471.3496\n",
            "Loss: 3918.4236\n",
            "Loss: 15.7877\n",
            "Loss: 16.4939\n",
            "Loss: 12.0822\n",
            "Loss: 9.6459\n",
            "Loss: 21.2616\n",
            "Epoch: 055,  Train Acc: 0.2125, Test Acc: 0.2002\n",
            "Loss: 13.7738\n",
            "Loss: 17.2449\n",
            "Loss: 17.9736\n",
            "Loss: 17.5593\n",
            "Loss: 5021.8896\n",
            "Loss: 14.8351\n",
            "Loss: 7423.3242\n",
            "Loss: 12.5466\n",
            "Loss: 11.5544\n",
            "Loss: 37.6204\n",
            "Loss: 3884.1575\n",
            "Loss: 24.3838\n",
            "Loss: 14.6346\n",
            "Epoch: 056,  Train Acc: 0.2338, Test Acc: 0.2121\n",
            "Loss: 12.6198\n",
            "Loss: 7552.3062\n",
            "Loss: 3857.2129\n",
            "Loss: 17.6467\n",
            "Loss: 11.2810\n",
            "Loss: 4986.7354\n",
            "Loss: 34.8879\n",
            "Loss: 18.0069\n",
            "Loss: 19.3106\n",
            "Loss: 18.9199\n",
            "Loss: 24.1848\n",
            "Loss: 21.5259\n",
            "Loss: 17.7424\n",
            "Epoch: 057,  Train Acc: 0.2112, Test Acc: 0.1966\n",
            "Loss: 5013.1235\n",
            "Loss: 20.5658\n",
            "Loss: 17.7714\n",
            "Loss: 15.5019\n",
            "Loss: 12.1597\n",
            "Loss: 41.5040\n",
            "Loss: 14.9172\n",
            "Loss: 13.5122\n",
            "Loss: 8.8649\n",
            "Loss: 3908.6150\n",
            "Loss: 7438.2808\n",
            "Loss: 9.9943\n",
            "Loss: 9.8498\n",
            "Epoch: 058,  Train Acc: 0.2787, Test Acc: 0.2529\n",
            "Loss: 4993.6045\n",
            "Loss: 14.9385\n",
            "Loss: 7554.5640\n",
            "Loss: 10.5853\n",
            "Loss: 12.3944\n",
            "Loss: 11.6362\n",
            "Loss: 3905.2437\n",
            "Loss: 26.1077\n",
            "Loss: 19.2055\n",
            "Loss: 16.6706\n",
            "Loss: 18.5499\n",
            "Loss: 15.8350\n",
            "Loss: 16.0900\n",
            "Epoch: 059,  Train Acc: 0.2250, Test Acc: 0.2075\n",
            "Loss: 40.5087\n",
            "Loss: 16.2583\n",
            "Loss: 9.6382\n",
            "Loss: 14.2305\n",
            "Loss: 11.1716\n",
            "Loss: 14.1423\n",
            "Loss: 3890.3679\n",
            "Loss: 5055.1118\n",
            "Loss: 13.3044\n",
            "Loss: 9.2086\n",
            "Loss: 10.9069\n",
            "Loss: 7487.6021\n",
            "Loss: 11.9570\n",
            "Epoch: 060,  Train Acc: 0.2838, Test Acc: 0.2539\n",
            "Loss: 8.9112\n",
            "Loss: 11.7723\n",
            "Loss: 12.9888\n",
            "Loss: 12.6561\n",
            "Loss: 10.5471\n",
            "Loss: 3928.8108\n",
            "Loss: 7530.6797\n",
            "Loss: 32.5509\n",
            "Loss: 11.9272\n",
            "Loss: 5025.3433\n",
            "Loss: 14.5981\n",
            "Loss: 8.2333\n",
            "Loss: 20.5158\n",
            "Epoch: 061,  Train Acc: 0.2625, Test Acc: 0.2453\n",
            "Loss: 4978.0928\n",
            "Loss: 17.5511\n",
            "Loss: 16.6646\n",
            "Loss: 9.2946\n",
            "Loss: 14.8862\n",
            "Loss: 7462.6992\n",
            "Loss: 14.3908\n",
            "Loss: 3905.8481\n",
            "Loss: 13.6755\n",
            "Loss: 15.5683\n",
            "Loss: 17.6376\n",
            "Loss: 25.5519\n",
            "Loss: 14.0349\n",
            "Epoch: 062,  Train Acc: 0.1913, Test Acc: 0.1853\n",
            "Loss: 14.9178\n",
            "Loss: 11.9386\n",
            "Loss: 14.5108\n",
            "Loss: 7419.7764\n",
            "Loss: 12.6816\n",
            "Loss: 5020.0854\n",
            "Loss: 3871.4419\n",
            "Loss: 39.9759\n",
            "Loss: 15.7605\n",
            "Loss: 19.8767\n",
            "Loss: 29.3300\n",
            "Loss: 18.3585\n",
            "Loss: 24.0919\n",
            "Epoch: 063,  Train Acc: 0.2150, Test Acc: 0.2020\n",
            "Loss: 17.0731\n",
            "Loss: 5035.2217\n",
            "Loss: 15.6000\n",
            "Loss: 17.1979\n",
            "Loss: 15.4232\n",
            "Loss: 16.8957\n",
            "Loss: 20.8409\n",
            "Loss: 31.0030\n",
            "Loss: 3896.6006\n",
            "Loss: 12.6839\n",
            "Loss: 12.3938\n",
            "Loss: 7462.4155\n",
            "Loss: 10.1143\n",
            "Epoch: 064,  Train Acc: 0.2825, Test Acc: 0.2559\n",
            "Loss: 11.5057\n",
            "Loss: 11.4695\n",
            "Loss: 5048.3901\n",
            "Loss: 16.9810\n",
            "Loss: 9.6334\n",
            "Loss: 8.8851\n",
            "Loss: 35.7601\n",
            "Loss: 7538.8320\n",
            "Loss: 3915.5771\n",
            "Loss: 14.9022\n",
            "Loss: 10.7621\n",
            "Loss: 13.2653\n",
            "Loss: 10.3886\n",
            "Epoch: 065,  Train Acc: 0.2750, Test Acc: 0.2524\n",
            "Loss: 14.4494\n",
            "Loss: 13.6690\n",
            "Loss: 10.7853\n",
            "Loss: 31.1119\n",
            "Loss: 7.9581\n",
            "Loss: 10.9807\n",
            "Loss: 11.8820\n",
            "Loss: 9.8238\n",
            "Loss: 3907.4585\n",
            "Loss: 7492.3086\n",
            "Loss: 9.9345\n",
            "Loss: 5012.8892\n",
            "Loss: 8.2641\n",
            "Epoch: 066,  Train Acc: 0.2812, Test Acc: 0.2609\n",
            "Loss: 11.8037\n",
            "Loss: 17.3509\n",
            "Loss: 11.0554\n",
            "Loss: 3920.2048\n",
            "Loss: 10.1530\n",
            "Loss: 5048.9204\n",
            "Loss: 13.3356\n",
            "Loss: 7487.3984\n",
            "Loss: 14.2560\n",
            "Loss: 10.2630\n",
            "Loss: 18.8552\n",
            "Loss: 15.8273\n",
            "Loss: 14.6606\n",
            "Epoch: 067,  Train Acc: 0.2100, Test Acc: 0.2008\n",
            "Loss: 16.9674\n",
            "Loss: 19.0465\n",
            "Loss: 18.3452\n",
            "Loss: 10.7809\n",
            "Loss: 3877.5315\n",
            "Loss: 15.2620\n",
            "Loss: 13.9492\n",
            "Loss: 11.9355\n",
            "Loss: 12440.6455\n",
            "Loss: 29.9449\n",
            "Loss: 11.2595\n",
            "Loss: 16.4933\n",
            "Loss: 10.2569\n",
            "Epoch: 068,  Train Acc: 0.2213, Test Acc: 0.2130\n",
            "Loss: 44.8111\n",
            "Loss: 10.2166\n",
            "Loss: 17.7389\n",
            "Loss: 12.1529\n",
            "Loss: 14.3265\n",
            "Loss: 7415.4038\n",
            "Loss: 3929.6755\n",
            "Loss: 12.1145\n",
            "Loss: 11.3665\n",
            "Loss: 4980.0630\n",
            "Loss: 19.0619\n",
            "Loss: 14.6688\n",
            "Loss: 18.3538\n",
            "Epoch: 069,  Train Acc: 0.2150, Test Acc: 0.2074\n",
            "Loss: 19.0093\n",
            "Loss: 14.8926\n",
            "Loss: 9.4722\n",
            "Loss: 20.6981\n",
            "Loss: 35.2683\n",
            "Loss: 17.9808\n",
            "Loss: 9.5374\n",
            "Loss: 3925.3684\n",
            "Loss: 7411.7651\n",
            "Loss: 4997.6372\n",
            "Loss: 17.4359\n",
            "Loss: 12.9108\n",
            "Loss: 12.0364\n",
            "Epoch: 070,  Train Acc: 0.2250, Test Acc: 0.2189\n",
            "Loss: 14.6769\n",
            "Loss: 14.7401\n",
            "Loss: 13.5063\n",
            "Loss: 15.1669\n",
            "Loss: 12.6783\n",
            "Loss: 14.3999\n",
            "Loss: 3912.9460\n",
            "Loss: 11.3392\n",
            "Loss: 7504.6621\n",
            "Loss: 20.1838\n",
            "Loss: 12.3386\n",
            "Loss: 5002.0483\n",
            "Loss: 14.0734\n",
            "Epoch: 071,  Train Acc: 0.2475, Test Acc: 0.2295\n",
            "Loss: 9.0720\n",
            "Loss: 16.9198\n",
            "Loss: 34.8999\n",
            "Loss: 12.5050\n",
            "Loss: 16.1726\n",
            "Loss: 11.0294\n",
            "Loss: 12487.8486\n",
            "Loss: 16.6345\n",
            "Loss: 20.7542\n",
            "Loss: 17.2156\n",
            "Loss: 3839.3022\n",
            "Loss: 13.1081\n",
            "Loss: 14.5791\n",
            "Epoch: 072,  Train Acc: 0.2162, Test Acc: 0.2057\n",
            "Loss: 12.1882\n",
            "Loss: 17.7704\n",
            "Loss: 12.9371\n",
            "Loss: 7461.4937\n",
            "Loss: 25.1312\n",
            "Loss: 13.1527\n",
            "Loss: 15.2711\n",
            "Loss: 17.2960\n",
            "Loss: 5008.4150\n",
            "Loss: 36.2072\n",
            "Loss: 3851.2366\n",
            "Loss: 15.1687\n",
            "Loss: 16.8928\n",
            "Epoch: 073,  Train Acc: 0.2162, Test Acc: 0.2042\n",
            "Loss: 19.0905\n",
            "Loss: 16.2434\n",
            "Loss: 5033.3452\n",
            "Loss: 31.3462\n",
            "Loss: 18.1738\n",
            "Loss: 13.9558\n",
            "Loss: 3893.5256\n",
            "Loss: 35.8910\n",
            "Loss: 7511.1025\n",
            "Loss: 10.9689\n",
            "Loss: 14.5342\n",
            "Loss: 19.7901\n",
            "Loss: 21.3699\n",
            "Epoch: 074,  Train Acc: 0.2225, Test Acc: 0.2204\n",
            "Loss: 3886.6223\n",
            "Loss: 12.9624\n",
            "Loss: 10.2796\n",
            "Loss: 5026.1406\n",
            "Loss: 15.0142\n",
            "Loss: 19.6525\n",
            "Loss: 16.0680\n",
            "Loss: 14.9695\n",
            "Loss: 35.6648\n",
            "Loss: 14.8870\n",
            "Loss: 14.5675\n",
            "Loss: 11.3744\n",
            "Loss: 14773.1729\n",
            "Epoch: 075,  Train Acc: 0.2550, Test Acc: 0.2413\n",
            "Loss: 14.5972\n",
            "Loss: 11.3703\n",
            "Loss: 13.2292\n",
            "Loss: 5032.9883\n",
            "Loss: 16.9168\n",
            "Loss: 15.7565\n",
            "Loss: 41.4160\n",
            "Loss: 14.9644\n",
            "Loss: 19.3119\n",
            "Loss: 11267.2617\n",
            "Loss: 16.0138\n",
            "Loss: 20.2629\n",
            "Loss: 14.9608\n",
            "Epoch: 076,  Train Acc: 0.1938, Test Acc: 0.1905\n",
            "Loss: 11292.6553\n",
            "Loss: 23.4125\n",
            "Loss: 31.7124\n",
            "Loss: 24.5820\n",
            "Loss: 4975.7163\n",
            "Loss: 30.0648\n",
            "Loss: 29.7689\n",
            "Loss: 27.1636\n",
            "Loss: 21.8948\n",
            "Loss: 29.9753\n",
            "Loss: 28.8199\n",
            "Loss: 26.3837\n",
            "Loss: 24.8836\n",
            "Epoch: 077,  Train Acc: 0.2112, Test Acc: 0.1926\n",
            "Loss: 19.4480\n",
            "Loss: 23.7545\n",
            "Loss: 12.5879\n",
            "Loss: 10.6898\n",
            "Loss: 3942.6499\n",
            "Loss: 12.8453\n",
            "Loss: 5016.1904\n",
            "Loss: 15.0629\n",
            "Loss: 13.1468\n",
            "Loss: 10.1441\n",
            "Loss: 11.5352\n",
            "Loss: 7497.2471\n",
            "Loss: 14.3612\n",
            "Epoch: 078,  Train Acc: 0.2913, Test Acc: 0.2520\n",
            "Loss: 9.0291\n",
            "Loss: 11.8664\n",
            "Loss: 5018.5854\n",
            "Loss: 10.2947\n",
            "Loss: 17.7594\n",
            "Loss: 3910.6055\n",
            "Loss: 10.6617\n",
            "Loss: 13.9769\n",
            "Loss: 14.2169\n",
            "Loss: 13.1585\n",
            "Loss: 7479.0142\n",
            "Loss: 33.3263\n",
            "Loss: 13.5305\n",
            "Epoch: 079,  Train Acc: 0.2612, Test Acc: 0.2395\n",
            "Loss: 10.6434\n",
            "Loss: 11.7926\n",
            "Loss: 9.7345\n",
            "Loss: 13.9626\n",
            "Loss: 5034.9541\n",
            "Loss: 38.8409\n",
            "Loss: 13.8256\n",
            "Loss: 13.8037\n",
            "Loss: 7452.1138\n",
            "Loss: 3946.2417\n",
            "Loss: 14.5749\n",
            "Loss: 12.6016\n",
            "Loss: 13.1178\n",
            "Epoch: 080,  Train Acc: 0.2550, Test Acc: 0.2351\n",
            "Loss: 13.8379\n",
            "Loss: 8.7523\n",
            "Loss: 10.2447\n",
            "Loss: 14.5588\n",
            "Loss: 16454.7539\n",
            "Loss: 11.5568\n",
            "Loss: 13.5297\n",
            "Loss: 16.4576\n",
            "Loss: 18.2794\n",
            "Loss: 21.3277\n",
            "Loss: 12.1975\n",
            "Loss: 15.5037\n",
            "Loss: 12.6541\n",
            "Epoch: 081,  Train Acc: 0.2437, Test Acc: 0.2332\n",
            "Loss: 34.9695\n",
            "Loss: 16281.0439\n",
            "Loss: 18.7707\n",
            "Loss: 17.2271\n",
            "Loss: 15.2678\n",
            "Loss: 15.0411\n",
            "Loss: 20.3068\n",
            "Loss: 19.3287\n",
            "Loss: 20.2313\n",
            "Loss: 17.6701\n",
            "Loss: 16.6727\n",
            "Loss: 13.2605\n",
            "Loss: 15.6077\n",
            "Epoch: 082,  Train Acc: 0.2338, Test Acc: 0.2249\n",
            "Loss: 21.8585\n",
            "Loss: 9.7279\n",
            "Loss: 37.3045\n",
            "Loss: 10.9238\n",
            "Loss: 10.1029\n",
            "Loss: 3879.2349\n",
            "Loss: 12.6373\n",
            "Loss: 13.8183\n",
            "Loss: 6.3225\n",
            "Loss: 4970.0986\n",
            "Loss: 9.9262\n",
            "Loss: 7492.3823\n",
            "Loss: 13.0295\n",
            "Epoch: 083,  Train Acc: 0.2725, Test Acc: 0.2528\n",
            "Loss: 14.4822\n",
            "Loss: 8.1935\n",
            "Loss: 5025.5894\n",
            "Loss: 15.4625\n",
            "Loss: 17.1613\n",
            "Loss: 32.0320\n",
            "Loss: 9.5159\n",
            "Loss: 13.3955\n",
            "Loss: 8.2105\n",
            "Loss: 15.1981\n",
            "Loss: 10.5978\n",
            "Loss: 11321.7383\n",
            "Loss: 9.4696\n",
            "Epoch: 084,  Train Acc: 0.2575, Test Acc: 0.2467\n",
            "Loss: 3843.5322\n",
            "Loss: 40.4434\n",
            "Loss: 16.8409\n",
            "Loss: 14.6132\n",
            "Loss: 7452.1719\n",
            "Loss: 11.8697\n",
            "Loss: 15.4076\n",
            "Loss: 20.5533\n",
            "Loss: 19.9658\n",
            "Loss: 15.2004\n",
            "Loss: 11.0663\n",
            "Loss: 19.6684\n",
            "Loss: 10042.3760\n",
            "Epoch: 085,  Train Acc: 0.2313, Test Acc: 0.2132\n",
            "Loss: 13.8052\n",
            "Loss: 15.9078\n",
            "Loss: 4993.8110\n",
            "Loss: 22.2714\n",
            "Loss: 3800.2175\n",
            "Loss: 16.3603\n",
            "Loss: 20.0180\n",
            "Loss: 45.7758\n",
            "Loss: 14.1081\n",
            "Loss: 21.9442\n",
            "Loss: 7423.5508\n",
            "Loss: 19.5382\n",
            "Loss: 19.7336\n",
            "Epoch: 086,  Train Acc: 0.2050, Test Acc: 0.1983\n",
            "Loss: 16.3024\n",
            "Loss: 17.1197\n",
            "Loss: 22.9945\n",
            "Loss: 20.4570\n",
            "Loss: 7411.0264\n",
            "Loss: 12.2663\n",
            "Loss: 12.7822\n",
            "Loss: 5016.2983\n",
            "Loss: 28.7441\n",
            "Loss: 14.9480\n",
            "Loss: 3848.4263\n",
            "Loss: 15.3058\n",
            "Loss: 14.6416\n",
            "Epoch: 087,  Train Acc: 0.2238, Test Acc: 0.2084\n",
            "Loss: 22.1676\n",
            "Loss: 18.3306\n",
            "Loss: 41.5582\n",
            "Loss: 14.9553\n",
            "Loss: 5004.1665\n",
            "Loss: 15.9214\n",
            "Loss: 21.1845\n",
            "Loss: 16.9036\n",
            "Loss: 14.8822\n",
            "Loss: 7405.2090\n",
            "Loss: 3883.0684\n",
            "Loss: 18.6522\n",
            "Loss: 20.2119\n",
            "Epoch: 088,  Train Acc: 0.2300, Test Acc: 0.2157\n",
            "Loss: 20.0778\n",
            "Loss: 18.8000\n",
            "Loss: 10.0240\n",
            "Loss: 18.7969\n",
            "Loss: 7347.4282\n",
            "Loss: 10.6685\n",
            "Loss: 5008.8330\n",
            "Loss: 19.9013\n",
            "Loss: 18.2016\n",
            "Loss: 3923.5747\n",
            "Loss: 17.3388\n",
            "Loss: 17.4344\n",
            "Loss: 18.5521\n",
            "Epoch: 089,  Train Acc: 0.2137, Test Acc: 0.1975\n",
            "Loss: 17.4883\n",
            "Loss: 16.2481\n",
            "Loss: 17.9492\n",
            "Loss: 21.6134\n",
            "Loss: 19.4178\n",
            "Loss: 12.4323\n",
            "Loss: 12.8632\n",
            "Loss: 7446.6860\n",
            "Loss: 14.6279\n",
            "Loss: 3842.9329\n",
            "Loss: 4989.2183\n",
            "Loss: 14.4053\n",
            "Loss: 11.7091\n",
            "Epoch: 090,  Train Acc: 0.2300, Test Acc: 0.2152\n",
            "Loss: 17.9777\n",
            "Loss: 19.8446\n",
            "Loss: 7373.3389\n",
            "Loss: 12.2947\n",
            "Loss: 21.2091\n",
            "Loss: 19.7066\n",
            "Loss: 16.3022\n",
            "Loss: 21.2601\n",
            "Loss: 21.1499\n",
            "Loss: 3880.2051\n",
            "Loss: 21.9053\n",
            "Loss: 4983.0840\n",
            "Loss: 10.5263\n",
            "Epoch: 091,  Train Acc: 0.2112, Test Acc: 0.1950\n",
            "Loss: 3809.9963\n",
            "Loss: 49.3850\n",
            "Loss: 19.5991\n",
            "Loss: 19.5563\n",
            "Loss: 20.0565\n",
            "Loss: 7387.2827\n",
            "Loss: 23.7490\n",
            "Loss: 24.6902\n",
            "Loss: 17.3925\n",
            "Loss: 21.3889\n",
            "Loss: 21.7185\n",
            "Loss: 4956.8711\n",
            "Loss: 18.9095\n",
            "Epoch: 092,  Train Acc: 0.2087, Test Acc: 0.2002\n",
            "Loss: 17.6729\n",
            "Loss: 25.3574\n",
            "Loss: 12.7377\n",
            "Loss: 13.8612\n",
            "Loss: 22.1600\n",
            "Loss: 7464.4775\n",
            "Loss: 23.2927\n",
            "Loss: 12.4518\n",
            "Loss: 12.1434\n",
            "Loss: 9.1759\n",
            "Loss: 11.6100\n",
            "Loss: 8853.5000\n",
            "Loss: 14.5894\n",
            "Epoch: 093,  Train Acc: 0.2462, Test Acc: 0.2280\n",
            "Loss: 10.2527\n",
            "Loss: 35.4246\n",
            "Loss: 13.8940\n",
            "Loss: 8.4948\n",
            "Loss: 7434.9497\n",
            "Loss: 15.1534\n",
            "Loss: 19.9275\n",
            "Loss: 3868.3289\n",
            "Loss: 16.6156\n",
            "Loss: 19.0650\n",
            "Loss: 19.0448\n",
            "Loss: 23.3896\n",
            "Loss: 10068.0488\n",
            "Epoch: 094,  Train Acc: 0.2200, Test Acc: 0.1999\n",
            "Loss: 4936.0688\n",
            "Loss: 14.4553\n",
            "Loss: 21.1632\n",
            "Loss: 21.1525\n",
            "Loss: 16.6854\n",
            "Loss: 7459.1689\n",
            "Loss: 3784.6826\n",
            "Loss: 25.2602\n",
            "Loss: 43.4371\n",
            "Loss: 27.5525\n",
            "Loss: 27.2721\n",
            "Loss: 24.7061\n",
            "Loss: 24.4225\n",
            "Epoch: 095,  Train Acc: 0.1888, Test Acc: 0.1784\n",
            "Loss: 3813.7095\n",
            "Loss: 21.2807\n",
            "Loss: 24.9771\n",
            "Loss: 22.7185\n",
            "Loss: 22.2084\n",
            "Loss: 42.5141\n",
            "Loss: 5019.8574\n",
            "Loss: 15.5476\n",
            "Loss: 16.9745\n",
            "Loss: 20.7711\n",
            "Loss: 9.9627\n",
            "Loss: 10.8380\n",
            "Loss: 14702.5469\n",
            "Epoch: 096,  Train Acc: 0.2450, Test Acc: 0.2251\n",
            "Loss: 14.9126\n",
            "Loss: 20.6331\n",
            "Loss: 14.4520\n",
            "Loss: 16.5631\n",
            "Loss: 3805.6499\n",
            "Loss: 7374.5210\n",
            "Loss: 21.5076\n",
            "Loss: 19.7196\n",
            "Loss: 4973.4443\n",
            "Loss: 21.0535\n",
            "Loss: 23.3509\n",
            "Loss: 17.7419\n",
            "Loss: 52.7293\n",
            "Epoch: 097,  Train Acc: 0.1825, Test Acc: 0.1710\n",
            "Loss: 31.1870\n",
            "Loss: 4903.2197\n",
            "Loss: 31.7425\n",
            "Loss: 23.6586\n",
            "Loss: 23.3604\n",
            "Loss: 3837.2334\n",
            "Loss: 22.0407\n",
            "Loss: 24.0607\n",
            "Loss: 7345.7646\n",
            "Loss: 49.7687\n",
            "Loss: 23.4343\n",
            "Loss: 26.7785\n",
            "Loss: 38.1745\n",
            "Epoch: 098,  Train Acc: 0.1862, Test Acc: 0.1779\n",
            "Loss: 18.6090\n",
            "Loss: 4956.2915\n",
            "Loss: 24.4258\n",
            "Loss: 13.7444\n",
            "Loss: 47.2353\n",
            "Loss: 7230.3638\n",
            "Loss: 17.5867\n",
            "Loss: 27.7606\n",
            "Loss: 21.3785\n",
            "Loss: 3889.9978\n",
            "Loss: 16.0185\n",
            "Loss: 14.2532\n",
            "Loss: 23.7716\n",
            "Epoch: 099,  Train Acc: 0.1875, Test Acc: 0.1759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oVZHbFZtte2S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}